% !TEX root = ../padalreport.tex
\chapter{Data Structures and Layout Abstractions}
\label{ch:datastructures}


%Define your Area
%  Create definition of your research area
%  Describe key concepts that define your area or that were uncovered during the course of conversation
%  A few examples of work in that area (can refer back to talks on website, but no need to recount entire talk)

%Findings:
%■ Describe points/observations/discoveries/challenges/issues uncovered in the session
 %● Distill into summary (major discoveries)
 %● can refer back to presentations for details
 %● Can also use data from panel discussions
%■ Identify areas of agreement
 %● Common approaches
 %● Common concerns
%■ Identify areas of disagreement
 %● what is the substantive cause of the disagreement (document)
 %● What metrics/information/research are needed to compare/resolve
%■ Identify Gaps
 %● What is missing?

%Recommendations
%■ Opportunities for standardization of mature technologies where the is substantial agreement or commonality
 %● Have we met the necessary conditions for standardization (is the area well enough understood, are the elements of existing implementations sufficiently similar, are the benefits clearly demonstrated, is there a user community?)
 %● What should we standardize? ( Low­hanging fruit )
 %● How can we influence standards committees? (e.g. C++17standards committee?)
%■ Define research agenda for new ideas or areas where there is insufficient information to choose a final implementation ( What areas need more research?)
 %● identify research thrust
 %● what are the opportunities
 %● what needs to be done
 %● What needs to be prioritized?
 %● What resources would be required (estimate size/complexity ofthe problem if you can)
%■ How do we create a user community? (bonus question)

\section{Introduction}
\note{Scroll down to see the original outline}

There is a diversity of ways to organize and represent data structures.  One source of diversity is among users, based on what they find to be convenient, intuitive and expressive.  A second source is differences between what is natural to users and what leads to efficient performance on target architectures.  A third source of diversity arises from differences among target architectures in what organizations and representations are most efficient.  Rarely does a single abstraction effectively span these three kinds of diversity.  Our goals are to enable a range of abstractions, to converge on ways to specify abstractions and map among them, and to enable those abstractions to be freely and effectively layered without undue restriction.

Recently, a number of programming interfaces such as Kokkos, TiDA, OpenMP
extensions, GridTools, Dash, Array Extensions \cite{all} have arise to give developers more control over 
 data layout and to abstract the data layout itself from the application. 
 In this chapter, we discuss the key points when designing such abstractions, emerging approaches with (im)mature
 solutions, and potential research areas. Here, we focus on  locality management on data-parallel algorithms 
 and leave the discussion on task-oriented abstractions to Chapter~\ref{ch:taskmodels}.



Before going into further discussions, we define relevant terminology. 
%
% \note{I sent an email for discussion, will update this section based on the responses.}
%
A {\em data structure} is an organized collection of data residing in one or more {\em memory spaces}.
%
Memory spaces may have different access characteristics, e.g. NUMA nodes of different latencies; different coherence domains associated with subsets of CPUs, GPUs or co-processors; or different types of memories, e.g. cached, software-managed or persistent.
%
{\em Data decomposition} is the partitioning of a data structure's data into smaller chunks with the intent of assigning each chunk to a memory space or introducing parallelism across chunks. 
%
{\em Data placement} is the mapping of decomposed data structures' chunks to memory spaces.
%
%\note{Data distribution is the composition of data decomposition and data placement.}
%
%
%\note{It is too narrow to say that {\em Data layout} is the mapping of a data structure's chunk to the physical addressing scheme of the assigned memory space.}
{\em Data layout} is the arrangement of a data structure according to the addressing scheme used by a given abstraction layer.  But there may be multiple {\em abstraction layers}, which together serve a diversity of objectives, as outlined above.  For example, users may prefer to refer to struct members of an array (AoS), whereas an array of structures of arrays (AoSoA) layout may be more profitable at the physical storage level.  Physical layout may differ between a software-managed memory that uses Hilbert curves, and a hardware-managed cache, for example.  There must be a mapping among the data layouts in the various abstraction layers, and potentially in each of the memory spaces.
%
A computation accesses memory according to a {\em data access pattern} which is determined by the composition of (1) how the computation's parallel tasks traverse the data structure,
(2) how the computation's tasks are scheduled (i.e., the {\em execution policy}), 
(3) data layout,
(4) data placement, and
(5) data decomposition.
%
Performance is constrained by the cost (time and energy) of moving data in service of the computation, which is directly impacted by the computation's data access pattern.
%
{\em Data locality} is a proxy measure for the relative cost of moving different data to/from a given task as it executes; smaller ``distance'' implies smaller cost.
%
Locality has both spatial (memory space) and temporal (execution scheduling) considerations.

  
  
\section{Key Points}
It is encouraging that there is a shift towards a more data-centric programming in the research community. 
We consider the following design principles as important and desired by the application programmers.

\begin{itemize}
\item We seek to improve performance by controlling the separate components (traversal, execution policy, data layout, data placement, and data decomposition) whose composition determines a computation's data access pattern. 
%
\item Separation of concerns is important to maximize expressivity and optimize performance. That principle is applied to the distinction between a logical, semantic specification, and lower-level controls over the physical implementation.
 At the semantic level, scalar work is mapped onto parallel data collections, using logical abstractions of data layout which best promote productivity. Domain experts can also expose semantic characteristics like reference patterns that can inform trade-offs made by tools.
%
\item A computation's algorithm is expressed in terms of operations on certain abstract data types, such as matrices, trees, etc. The code usually expresses data traversal patterns at high level, such as accessing the parent node in a tree, or the elements in a row of a matrix. This expresses the {\em algorithmic locality} of the data, which may be not related to the {\em actual} locality of the data access.  The actual locality is obtained when the algorithm's traversals, tasks, and data structures are mapped to the physical architecture. \
%
\item The efficiency of a computation's on-node data access pattern may depend upon the architecture of the computer on which it executes.  Performance may be improved by choosing a data layout appropriate for the architecture.  This choice can be made without modifying the computations source code if the data structure has a {\em polymorphic data layout}.
%
\item Performance tuners, who may be distinct from the domain experts, may exercise control over performance with a set of interfaces which can be distinct from those that specify semantics. 
%
\item Through these interfaces, they may decompose, distribute and map parallel data collections onto efficient physical layouts with specialized characteristics.
\end{itemize}

\note{Move the following to discussion?}
The key point of separation of concerns is of offering, to the user of
the interface, an architecture agnostic {\em abstract machine}
(AM). An AM is necessary to express an algorithm, being it a
functional language or a Turing machine. An algorithm written for an
AM must be translated into program for a {\em physical machine} (PM),
which can be closely related to AM or completely different. The
translation effort depends on the ``distance'' between the AM and the
PM. Since there are many different PMs, and the lifetime of
applications should be much longer that the lifetime of an
architecture, the usual request is that an algorithm for an AM should
be executed efficiently in the widest possible class of forseeable
PMs. This is the well know problem of {\em portable efficiency}. From
this perspective an AM should be distant from PMs for two reasons:
first it gives the user an uniform view of the programming space,
often at a much higher level of abstraction than any specific
programming model for a PM; second, the hope is that by being
equidistant from any PM the translation can lead to equally efficient
implementations with similar effort.

The interfaces the Authors of this report are developing, the already
cited Kokkos, TiDA, OpenMP extensions, GridTools, Dash, Array
Extensions, provide AMs at widely different abstraction levels. Some
as DASH provide a PGAS abstraction in C++, so that DASH AM is
basically an universal parallel machine with the concept of (two
levels: local and remote) locality made explicit. GridTools provides a
set of libraries for expressing distributed memory implementations of
regular grid applications, like stencils. It is not meant to be
universal, in the sense that non regular grid applications should not
be expressed using Gridtools libraries, even though possible in
principle, for performance reasons. Since the constructs provided by
GridTools are high level and semi-functional, locality issues are
taken into account at the level of performance tuners and not by
application programmers. At user level the locality is take into
consideration only implicitly. The Kokkos library supports expressing
multidimensional arrays in C++, in which the polymorphic layout can be decided at
compile time. An algorithm written with Kokkos uses the AM of C++ with
the data specification and access provided by the interface of Kokkos
arrays. Locality is managed explicitly by matching the data layout
with the algorithm logical locality. \note{Not sure what to say about
  the others}. As can be seen, there is not a single way of treating
locality concerns, and there is not consensus on which one is the
best. Each of these approaches are appealing to different scenarios
that depends on the scope of the particular projects. In the case of
C++ libraries, anyway, there is the possibility of naturally building
higher level interfaces using lower level ones, for instance a DASH
multidimensional array could be implemented using Kokkos arrays, and
GridTools parallel algoritmhs could use DASH library, and Kokkos
arrays for storage, etc. This is a potential benefit from
interoprability that arises from using a commom language provided with
generic programming capabilities, as C++.

%\note{The followings were used to be in the terminology but I think we
%  center the discussion around them. Mauro: I think they should be
%  moved to the terminology section.}
%
%\begin{itemize}
% \item Memory access pattern: The memory access pattern of a computation is determined by the composition of the computation's algorithm, computation's execution policy, and layout of the computation's data structures.  The quality of a computation's memory access pattern is determined by the time or energy consumed accessing its data. 
% \note{This is now covered in the terminology .} 
%
%  \item Polymorphic layout: The quality of a computation's memory access pattern may depend upon the architecture of the computer on which it executes.  A data structure has a polymorphic layout if the layout can be changed to improve the memory access pattern without modifying the source code of computations depending upon that data structure.
%  \note{This is now covered in the key points.}
%
%  \item A data structure (-layout) has good locality (-behavior) with respect to an algorithm if operations on the data structure can be executed efficiently in terms of run-time and/or energy consumption. So locality is not a property of the data structure or layout alone, there is an execution/code component that determines if locality behavior is good.
%  \note{This may be adequately covered in the terminology.}
%
%  \item Algorithmic locality vs. actual/implementation locality: An algorithm is expressed in terms of operations on certain abstract data types, such as matrices, trees, etc. The algorithm code usually express access patterns to the data at high level, such as accessing the parent node in a tree, or the elements in a row of a matrix. This express a {\em logical locality}, that we refer to {\em algorithmic locality}, since it may be not related to the {\em actual} or {\em implementation} locality, that express the locality characteristics of locality of the code obtained by mapping the algorithm (maybe through a compiler) to the physical architecture. \note{Mauro: tried to clarify this. Does it work?}
%  \note{Tightened wording and moved to key points}
% \end{itemize}

\section{Emerging Approaches}

High performance computing presents scientists and performance tuners
with two key challenges: exposing parallelism and effectively
harvesting that parallelism.  A natural separation of concerns arises
from those two efforts, whereby the scope of effort for each of domain
experts and performance tuning experts can be limited, and the two may
be decoupled without overly restricting each other.  Charting a solid
path forward toward a clean separation of concerns, defining
appropriate levels of abstraction, and highlighting properties of
language interfaces that will be effective at managing data
abstractions are the subject of this effort.

Domain experts specify the work to be accomplished and they map that
work onto parallel data collections.  They want the freedom to use a
representation of data that is natural to them.  They don't want to be
concerned with performance-related details.  Performance tuning
experts want full control over performance, without having to become
domain experts.  So they want domain experts to fully expose
opportunities for parallelism, without overspecifying how that
parallelism is to be harvested.  This leads to a natural separation of
concerns between a logical abstraction layer at which semantics are
specified, and a lower, physical abstraction layer, at which
performance is tuned and the harvesting of parallelism on a particular
target machine is controled.  This separation of concerns allows code
modifications to be localized.  The use of abstraction allows
high-level expressions to be polymorphic across a variety of low-level
trade-offs at the physical implementation layer.  Several interfaces
are now emerging that maintain the discipline of this separation of
concerns, and that offer alternative ways of mapping between the
logical and physical abstraction layers.  Among these are Kokkos, TiDA,
and GridTools.

\section{Discussion}

This chapter of the report focuses on performance controls that are
used to manage data to achieve performance, rather than on how
parallelism is exposed at the semantic layer.  We address language
interface issues and provide a taxonomy of performance controls.
\note {It would also be good to highlight issues that can impact productivity, 
performance, and performance portability.  } We have identified some
areas of agreement on where to start in this overall effort.

In the area of language interfaces, some consensus was reached on
several points.  Differences in the objectives of domain experts and
performance tuning experts shape the set of language interface
attributes that are best suited for each.

At the semantic layer, language interfaces should be high level,
minimalist, and standardized.  Because the diversity of target
platforms, performance factors, and implementation details are
abstracted away at this level, the opportunity for simplicity and
consistency is greater.  Base languages can be a good long-term target
for providing ways for the user to expose parallelism and to describe
characteristics of how data is to be used.

There is greater innovation and less standardization in the area of
performance controls.  This suggests that they be implemented using
library interfaces.  This reduces the dependence on commercial
compilers, enables greater variety, and eases deployment where
target-specific optimizations are made.

C++ seems to provide some of the greatest opportunity for enabling
data layout abstraction in a base language.  By contrast, Fortran is
relatively inflexible, and scripting languages' polymorphic types
provide lots of flexibility to users, but have so little structure
that optimization is difficult.
\note {we need a much better articulation of that.}  

The choice of base language to express abstraction varies among
different groups. Some prefer standard languages such as Fortran and
C/C++ in order to maximize impact and leverage market breadth of the
supporting tool chain (e.g., compilers, debuggers, profilers).
Wherever profitable, there can be a push to ``redeem'' existing
languages by amending or extending them, e.g. via changes to the
specifications or by introducing new ABIs. 

C++ meta-programming can cover a significant fraction of the desired
capabilities, e.g. polymorphic data layout and execution policy.
Specialization can be hidden in template implementation and controlled
by template parameters.  For example, C++ templates enable users to
express data accesses in the body of the code in ways that are natural
and convenient, and manage the mapping from that logical abstraction
to an underlying layout which may be much better for performance in
the template definition.  In efforts like Kokkos, Arrow Street and
SIMD Building Blocks, \note {add references} compilers have
demonstrated an ability to ``see through'' those abstractions to
effectively harvest parallelism.  In the latter two efforts, the user
is required to explicitly provide a bidrectional mapping between
abstractions, which can be burdensome and error prone.  Efforts to
augment the C++ standard with better support for introspection appear
to be a promising path for easing that burden.  The ISO C++
standardization committee is addressing performant, on-node
parallelism for a future standard (e.g., C++17).  Even though a huge
number of applications are implemented in Fortran, there is a concern
about Fortran's lack of extensibility in terms of lambdas and
templates.

There's a concern that features that are needed to ``get us to
exascale'' are lacking in existing, standard languages.  There are at
least three options for mitigating that: extend standard languages,
augment standard languages with embedded domain-specific languages, or
depart from standards with specialized languages.  Different language
rules may be required to overcome limitations imposed by current
languages. For example, C exposes physical data layout, and limits a
compiler's ability to modify the data layout. Source to source
translators are still subject to language rules, whereas new languages
may remove such limitations through abstraction.  In conclusion, there
is no single language to physically implement the layout abstractions.

Performance-related controls pertain to data and to execution policy.  These may vary in their function, scope and granularity.
    \begin{itemize}
    \item Data controls may be used to manage:
      \begin{itemize} 
      \item Decomposition, which tends to be either trivial (parameterizable and automatic) or not (explicit)
      \item Binding to storage: to a particular type of memory (e.g. read only, streaming), to a phase-dependent depth in the memory hierarchy (prefetching, marking non-temporal), or to memory structures which support different kinds of sharing (SW managed, cached)
      \item Mechanisms for, and timing of, distribution to data space/locality bindings
      \item Data layout
      \end{itemize}
    \item Execution policy controls may be used to manage
      \begin{itemize} 
      \item Decomposition of work, e.g. iterations, hierarchical tasks
      \item Ordering of work, e.g. recursive subdivision, work stealing
      \item Association of work with data, e.g. moving work to data, binding to hierarchical domains like a node, thread or a SIMD lane
      \end{itemize}
    \item These controls may be applied at different scopes and granularities through a varity of mechanisms
      \begin{itemize} 
      \item Data types - global, fine-grained, can vary by call site
      \item Function or construct modifiers - local coarse-grained, can vary within a scope
      \item Environmental variable controls - global policies
      \end{itemize}


<Summarize areas of low-hanging fruit.>

Libraries? 
Flavors of functional programming ?

\section{Research Areas}

<Discuss data model: motivation, value, issues.>

<removing barriers to freedom of abstraction>

<portable efficiency>

\section{OUTLINE}

HIGHLIGHTS

\begin{itemize}
\item SCOPE
  \begin{itemize}
  \item In this chapter, we discuss language and library interfaces that help manage programming abstractions for data locality, particularly for data structures and data layout. 
  \end{itemize}
\item KEY POINTS
  \begin{itemize}
  \item \note{Didem: I think this should appear in the introduction of the entire report.}What are the {\em easy} and the {\em complex} parts of algorithm design? I think the {\em easy} should include parallelism. From the implementation point of view this may be different, but compared with the challenges of locality, parallelism should be considered easy and high level. What is the level of ``algorithmic locality'' that we want to be able to specify? Is local/non-local distinction sufficient?
  \item From the requirements of the applications (and scalability) we focus on data-parallel algorithms (even though we may use task oriented abstractions and runtimes).
  \item The lack of a single abstract machine (programming model) to program for performance imposes the choice of data-structure specific constructs and specific implementations of those for different platforms (for now this is an empirical observation)
  \item \note{not sure I got this item, it seems similar to the item right above}The diversity of the architectures also forces these constructs to work at level of {\em means of combination/composition} (it's not sufficient to provide very efficient primitive operations, like BLAS).
  \item Separation of concerns is important to maximize expressivity and optimize performance.  That principle is applied to the distinction between a logical, semantic specification, and lower-level controls over the physical implementation.
  \item At the semantic level, scalar work is mapped onto parallel data collections, using logical abstractions of data layout which best promote productivity.  Domain experts can also expose semantic characteristics like reference patterns that can inform trade-offs made by tools.
  \item Performance tuners, who may be distinct from the domain experts, may exercise control over performance with a set of interfaces which can be distinct from those that specify semantics.  Through these interfaces, they may 
    \begin{itemize}
    \item decompose, distribute and map parallel data collections onto efficient physical layouts with specialized characteristics, 
    \item map parallel work onto underlying hardware mechanisms for supporting parallelism, and 
    \item exercise control over temporal sequencing of work and movement of data for locality.
    \end{itemize}
  \item Some (im)mature solutions implemented in different languages include: Kokkos, TiDA, OpenMP extensions, GridTools, Dash, Array Extensions
\end{itemize}


\item TERMINOLOGY (define each of these up front)
  \begin{itemize}

 \item Data structure: A organized collection of data residing in one or more memory spaces. 

  \item Layout (of data structure):
    The mapping of a data structure into one or more memory spaces, typically with the intent of efficient and performant access by a collection of computations.

    Example: A 2D matrix of size 100x100 holding integers is a data structure: a semantic/logical entity in which a programmer thinks. Storing and processing the matrix in a computer requires a layout that maps the 2D matrix onto the 1D address space of the computer in some way. The mapping could be a simple linearization or it could be a more complex blocked (tiled) scheme.

  \item Memory space: A computer has multiple memory resources.  A single computer traditionally has main memory, one or more levels of hardware managed cache memory, and registers; where the main memory is the only memory space explicitly managed by a program.  Advanced architectures have heterogeneous memory for performance that must be managed by computations.  Examples of these memory spaces include CPUs' non-uniform memory access (NUMA) regions, separate GPU memory, and software-managed on-chip memory.

 
  \item Distributed data structure / parallel data structure: not sure we should use either of those terms, but if we do we should make sure what we mean: is the data distributed over multiple nodes/address spaces? is there concurrent access to the same data structure? 
      
  \item \note{Didem: should be part of the report intro} Locality: A measure of distance between data on a computer.  For example, do the data reside in the same compute node of a cluster, in the same memory space, in the same cache line?  [I can't think of a direct definition that doesn't require a whole lot of other definitions up front, so how about the following phenomenological definition?]

  \item Execution policy: How a computation's units of work are scheduled and mapped onto data collections. \note{is this the same thing as thread binding?}

  \item Memory access pattern: A computation accesses data structures according to its execution policy. 

  \item Memory access pattern: The memory access pattern of a computation is determined by the composition of the computation's algorithm, computation's execution policy, and layout of the computation's data structures.  The quality of a computation's memory access pattern is determined by the time or energy consumed accessing its data.  

  \item Polymorphic layout: The quality of a computation's memory access pattern may depend upon the architecture of the computer on which it executes.  A data structure has a polymorphic layout if the layout can be changed to improve the memory access pattern without modifying the source code of computations depending upon that data structure.

  \item A data structure (-layout) has good locality (-behavior) with respect to an algorithm if operations on the data structure can be executed efficiently in terms of run-time and/or energy consumption. So locality is not a property of the data structure or layout alone, there is an execution/code component that determines if locality behavior is good.

  \item Algorithmic locality vs. actual/implementation locality: Not sure I would know how to define these terms. What is algorithmic locality of matrix multiplication? 

  \item Logical, semantic level: programmer expresses the WHAT, exposes OPPORTUNITY in a natural expression; portable
  \item Portable efficiency
  \item Algorithmic locality vs. actual locality or implementation locality
  \item Physical, performance level: CONTROL over HOW, so as to meet performance goals; may be implementation specific
  \item Polymorphic: may take different forms, depending on the abstraction layer or optimization target
  \item Language interface: a spec or API used by a programmer, which may be part of the base language, a compiler-interpreted directive, or a library API [this may need work] 
  \item Language construct: something that can be identified as a {\em keyword} in a language interface and the grammar rules that applies to it.

  \item Binding: mapping from the logical to physical domain, e.g. for storage
  \item {\em What follows should be either filled in or dropped}
  \item control space(use execution space?)
  \item binding  (or execution policy ?)
  \item data layout
  \item data decomposition 
  \item data distribution 
  \item iteration space traversal (avoid using loop traversal, maybe use domain traversal?) maybe : {\em iteration patterns} to be paired with {\em access patterns}?
  \item access type
  \end{itemize}


\item AGREEMENTS
  \begin{itemize}
  \item Abstractions for performance portability are needed: Data layout, tile sizes, memory access patterns need to be tuned when application is moved between machines. [We may want to tweak that list.]
  \item The separation of logical from physical concerns enables:
    \begin{itemize}
    \item Separation of concerns between domain experts and performance tuning experts
    \item Maximal exposure of opportunity, vs. hard coding a particular trade-off
    \item Getting free of enslavement to restrictions or suboptimalities imposed at the logical level
    \item Minimizing, or at least localizing, code modification for control over performance
    \item Polymorphism across targets and abstraction layers
    \end{itemize}
  \item We need a data model to assess the data locality
    \begin{itemize}
    \item We have a model for parallelism but do not have a model for data locality
    \item Optimal trade-offs may shift over time and across target systems.  
    \item Models need to take into account the capabilities and capacities of computational elements, memory structures, and the network fabric 
    \item Models should reflect the consequences of various controls, such as the placement of work near data
    \end{itemize}
  \item It's easier to standardize high-level concepts, suggesting that
    \begin{itemize}
    \item Extensions for controls over how parallel work and data are managed may best be targeted at libraries and language interfaces, rather than base languages.  There's greater freedom for diversity there.
    \item Base languages are a good longer-term target for semantically exposing opportuniteis for parallelism (and locality?)
    \end{itemize}
  \item Low hanging fruit: 
    (1) multidimensional array support (in C and C++) 
    (2) runtime polymorphic data layout: 
    ideally change the layout in runtime (it should always be clear when an operation has performance costs),
    (3) compile time polymorphic layout: change the layout at compile time with minimal code modifications, 
    support layout in the type system 
  \item Performance-related controls pertain to data and to execution policy.  These may vary in their scope and granularity.
    \begin{itemize}
    \item Data controls may be used to manage:
      \begin{itemize} 
      \item Decomposition, which tends to be either trivial (parameterizable and automatic) or not (explicit)
      \item Binding to storage: to a particular type of memory (e.g. read only, streaming), to a phase-dependent depth in the memory hierarchy (prefetching, marking non-temporal), or to memory structures which support different kinds of sharing (SW managed, cached)
      \item Mechanisms for, and timing of, distribution to data space/locality bindings
      \item Data layout
      \end{itemize}
    \item Execution policy controls may be used to manage
      \begin{itemize} 
      \item Decomposition of work, e.g. iterations, hierarchical tasks
      \item Ordering of work, e.g. recursive subdivision, work stealing
      \item Association of work with data, e.g. moving work to data, binding to hierarchical domains like a node, thread or a SIMD lane
      \end{itemize}
    \item These controls may be applied at different scopes and granularities through a varity of mechanisms
      \begin{itemize} 
      \item Data types - global, fine-grained, can vary by call site
      \item Function or construct modifiers - local coarse-grained, can vary within a scope
      \item Environmental variable controls - global policies
      \end{itemize}
    \end{itemize}
  \item lambdas for domain traversal (or iteration space traversal) [is this now adequately covered below?]
  \end{itemize}
  
\item  DISAGREEMENTS
  \begin{itemize}
  \item Binding [could someone flesh out the opposing points of view?] Depending on the level at which a language/library stands (single thread, multicore chip, parallel distributed system) the binding is responsibility of the user or the system. I don't think we agree on what the level of abstraction is right, so we could not agree in the binding, I guess.
  \item support for memory spaces: can be hidden from the programmer or exposed [could someone flesh out the opposing points of view?]  Traditional architectures have hidden memory spaces within node through hardware supported movement of data through a cache memory hierarchy.  This implicit memory space management strategy has been applied to distributed memory clusters through PGAS programming models and runtimes.  There has is not a consensus on PGAS versus explicit management of data movement among clusters' compute nodes.  Advanced compute node architectures have heterogeneous memory spaces which must be managed for computational performance.  It is an open question as to whether a programming model can be deployed that implicitly manages these memory spaces and provides sufficient memory access quality.

  \item Choice of language interfaces
    \begin{itemize}
    \item Some prefer standard languages, in order to maximize impact and leverage market breadth of the supporting tool chain (e.g., compilers, debuggers, profilers).  Wherever profitable, there can be a push to ``redeem'' existing languages by amending or extending them, e.g. via changes to the spec or by introducing new ABIs.  It is noteworthy that the ISO C++ standardization committee intends to address performant, on-node parallelism in a future language standard.
    \item Others believe that specialized languages are required, e.g. to ``get us to exascale.''  Different language rules may be required to overcome limitations imposed by current languages.  For example, C exposes physical data layout, and limits a compiler's ability to re-layout data.  Source to source translators are still subject to language rules, whereas new languages may remove such limitations through abstraction.
    \item There's some agreement that C++ metaprogramming can cover a significant fraction of the desired capabilities, and that it's a middle road for being able to implement DSLs that are embedded within standard languages.  Specialization can be hidden in template implementation and controlled by template parameters.
    \item There's some concern about Fortran's lack of extensibility, e.g. in the direction of lambdas, templates and metaprogramming
    \end{itemize}
  \end{itemize}

\item GAPS (what is missing? not covered at the workshop)
  \begin{itemize}
  \item A data model for which data layout is more suitable for which algorithm? or metric for locality
  \item The mentioned distinction between WHAT and HOW is subtle. I think every developer is concerned with WHAT. As library/language developers we want our users to be concerned by certain WHAT that we turn into HOW by stating some lower level WHATs. In my work I can use a PGAS approach (in which locality is expressed as a here-or-there) underneath but hide it altogether to my user. I think we disagree at what level our users should express their programs. We agree that there must be a separation of concerns but not where the separation should be.
  \end{itemize}

\item RESEARCH AGENDA
  \begin{itemize}
\item If we speak of data locality, is a binary local/remote distinction enough or do we need a more fine-grained differentiation? If so, what is the best way to represent and measure this multi-level locality concept. Is "hierarchy" always the right concept and is a tree always a good representation?

\item What about horizontal locality management vs. vertical locality management? Do they require different abstractions or can they be handled in a uniform way?

  \item Identify minimal set of data and execution policy controls
  \item Compare/contrast available options for specifying those controls
  \item Identify gaps and prescribe steps toward closure of those gaps
  \item Converge on a minimally set of (semi-standard) solutions that provide adequate coverage
  \item Prove or disprove that an portable efficiency can be achieved with a single language (in order to prove or disprove that data-structure specific approaches are the only beign possible)
  \end{itemize}

\end{itemize}



